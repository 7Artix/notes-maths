
# 8.1 特征值与特征向量

## `定义1` $特征值与特征向量$

> 设 $\boldsymbol{A}$ 是 $n$ 阶方阵, $\boldsymbol{x}$ 为非零向量, 若存在数 $\lambda$ 使得下式成立:

$$
\boldsymbol{A}\boldsymbol{x} = \lambda\boldsymbol{x}
$$

> 则数 $\lambda$ 称为 $\boldsymbol{A}$ 的<font color=red><b>特征值</b></color> ( $Eigenvalue$ ) , <font color=red><b>非零向量</b></color> $\boldsymbol{x}$ 称为 $\boldsymbol{A}$ 的对应于 $\lambda$ 的<font color=red><b>特征向量</b></color> ( $Eigenvector$ ). 特征值可以是复数.

其含义为, 向量 $\boldsymbol{x}$ 在经过矩阵函数 $\boldsymbol{A}$ 的变换后没有改变, 或者只是缩放了. 

矩阵函数 $\boldsymbol{A}$ 必须是一个方阵, 这意味着这个变换要作用与原向量空间的所有维度的基. 如:
- 原本是2维空间的一组基, 能够张成整个二维平面, 这个变换矩阵应该是 $2\times2$ 的. 
- 原本是三维空间中的一个平面, 是由两个线性无关的3维向量张成的一个二维平面, 此时的变换矩阵也应该是 $2\times2$ 的, 注意, 原本的两个3维向量构成的矩阵不是方阵是不关心的.

对于 $n$ 阶<font color=green><b>单位阵</b></color> $\boldsymbol{I}$ , $\boldsymbol{I}\boldsymbol{x} = \boldsymbol{I}, \boldsymbol{x} \in \mathbb{R}^n$ 始终成立, 因此向量空间 $\mathbb{R}^n$ 中的所有非零向量 $\boldsymbol{x}$ 都是单位阵 $\boldsymbol{I}$ 的特征向量, 并且对应特征值都是 $1$ . 从含义上理解,  $n$ 阶单位阵 $\boldsymbol{I}$ 对应的变化就是完全不变, 因此, 所有非零向量都满足变换前后向量不变, 因此所有非零向量都是单位阵的特征向量.

> 若对应某个特征值的向量组成了一个向量空间, 则称该空间为特征值 $\lambda$ 的<font color=red><b>特征空间</b></color> ( $Eigenspace$ ).


## `定义2` $特征多项式和特征方程$

> 若:

$$
\boldsymbol{A} = 
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn} \\
\end{pmatrix}
$$

> 则 $|\boldsymbol{A} - \lambda\boldsymbol{I}| = 0$ 可以写作:

$$
|\boldsymbol{A} - \lambda\boldsymbol{I}| =
\begin{vmatrix}
a_{11}-\lambda & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22}-\lambda & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}-\lambda \\
\end{vmatrix} = 0
$$

> 其中 $|\boldsymbol{A} - \lambda\boldsymbol{I}|$ 展开后就是关于特征值 $\lambda$ 的多项式, 所以称之为<font color=red><b>特征多项式</b></color> ( $Characteristic\ polynomial$ ):

$$
|\boldsymbol{A} - \lambda\boldsymbol{I}| =
\begin{vmatrix}
a_{11}-\lambda & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22}-\lambda & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}-\lambda \\
\end{vmatrix} = 
c_0\lambda^n + c_1\lambda^{n-1} + \cdots + c_n
$$

> 进而 $|\boldsymbol{A} - \lambda\boldsymbol{I}| = 0$ 被称为<font color=red><b>特征方程</b></color> ( $Characteristic\ equation$ ).

至于为什么是一个行列式的形式:

根据特征值和特征向量的定义, 需要满足的是 $\boldsymbol{A}\boldsymbol{x} = \lambda\boldsymbol{x}$ . 该式可得:

$$
\boldsymbol{A}\boldsymbol{x} = \lambda\boldsymbol{x} \implies
(\boldsymbol{A} - \lambda\boldsymbol{I})\boldsymbol{x} = \boldsymbol{0} 
\overset{由于\boldsymbol{x}是非零向量}{\Longrightarrow}
|\boldsymbol{A} - \lambda\boldsymbol{I}| = 0
$$


## `定理1` 互异特征值对应的特征向量

> 已知 $\lambda_1,\lambda_2,\cdots,\lambda_m$ 是 $n$ 阶方阵 $\boldsymbol{A}$ 相异的特征值, 以及 $\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m$ 是 $\lambda_1,\lambda_2,\cdots,\lambda_m$ 对应的特征向量, 则向量组 $\{\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m\}$ 线性无关.


# 8.2 对角化

## `定义3` $对角化$

> 若 $n$ 阶方阵 $\boldsymbol{A}$ 有 $n$ 个线性无关的特征向量 $\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_n$ , 那么构造矩阵 $\boldsymbol{P} = (\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_n)$ , 可使得:

$$
\boldsymbol{A} = \boldsymbol{P}\boldsymbol{\Lambda}\boldsymbol{P}^{-1}
$$

> 其中 $\boldsymbol{\Lambda}$ 为如下对角阵:

$$
\boldsymbol{\Lambda} = 
\begin{pmatrix}
\lambda_1 & & & \\
& \lambda_2 & & \\
& & \ddots & \\
& & & \lambda_n \\
\end{pmatrix}
$$

> 其中 $\lambda_1,\lambda_2,\cdots,\lambda_n$ 为特征向量 $\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_n$ 对应的特征值, 该过程称为<font color=red><b>对角化</b></color> ( $Diagonalizable$ ).

对角化的过程是 $\boldsymbol{A} = \boldsymbol{P}\boldsymbol{\Lambda}\boldsymbol{P}^{-1}$ .


# 8.4 正交矩阵

## `定义4` $正交基$

> 已知 $\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_r$ 是向量空间 $\mathcal{V}$ 的一个基, 若两两正交, 即满足:

$$
\boldsymbol{p}_i \cdot \boldsymbol{p}_j = 0 , \quad i \neq j
$$

> 则称其为<font color=red><b>正交基</b></color> ( $Orthogonal basis$ ). 若还满足长度均为 $1$ , 则称为<font color=red><b>标准正交基</b></color> ( $Orthonormal basis$ ).


## `定义5` $正交矩阵$

> 若 $\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_n$ 是向量空间 $\mathbb{R}^n$ 的一个标准正交基, 那么由它们构造的 $n$ 阶方阵 $\boldsymbol{P}$ 称为<font color=red><b>正交矩阵</b></color> ( $Orthogonal \ matrix$ ):

$$
\boldsymbol{P} = (\boldsymbol{p}_1,\boldsymbol{p}_2,\cdots,\boldsymbol{p}_n)
$$

> $\boldsymbol{P}$ 一定满足:

$$
\boldsymbol{P}^T\boldsymbol{P} = \boldsymbol{P}^{-1}\boldsymbol{P} = \boldsymbol{I}
$$

> 即 $\boldsymbol{P}^T$ 就是 $\boldsymbol{P}$ 的逆矩阵.


# 8.5 施密特正交化

> 若 $\boldsymbol{x}_1,\boldsymbol{x}_2,\cdots,\boldsymbol{x}_n$ 是某向量空间中的一组基, 则可以通过下述方法找到该向量空间中的一组正交基 $\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_n$ , 该方法称为<font color=red><b>施密特正交化</b></color> ( $Gram-Schmidt \ process$ ):

$$
\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n
\xrightarrow{施密特正交化}
\left\{
\begin{array}{l}
\boldsymbol{v}_1=\boldsymbol{x}_1 \\
\boldsymbol{v}_2=
\boldsymbol{x}_2 - \dfrac{\boldsymbol{x}_2\cdot\boldsymbol{v}_1}{\boldsymbol{v}_1\cdot\boldsymbol{v}_1}\boldsymbol{v}_1 \\
\boldsymbol{v}_3=
\boldsymbol{x}_3 - \dfrac{\boldsymbol{x}_3\cdot\boldsymbol{v}_1}{\boldsymbol{v}_1\cdot\boldsymbol{v}_1}\boldsymbol{v}_1 - \dfrac{\boldsymbol{x}_3\cdot\boldsymbol{v}_2}{\boldsymbol{v}_2\cdot\boldsymbol{v}_2}\boldsymbol{v}_2 \\
\qquad\cdots \\
\boldsymbol{v}_n=
\boldsymbol{x}_n - \dfrac{\boldsymbol{x}_n\cdot\boldsymbol{v}_1}{\boldsymbol{v}_1\cdot\boldsymbol{v}_1}\boldsymbol{v}_1 - \cdots - 
\dfrac{\boldsymbol{x}_n\cdot\boldsymbol{v}_{n-1}}{\boldsymbol{v}_{n-1}\cdot\boldsymbol{v}_{n-1}}\boldsymbol{v}_{n-1}
\end{array}
\right.
$$

